{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["**3. Tumour Segmentation**\n","=\n","\n","***Advanced Methods of Artificial Vision - Final Project***\n","\n","**Authors:** *Alejandro Araque Robles, Ander Bodegas Díez, Lucía Gonzalez Ratón y Gonzalo Sabando Alonso*"],"metadata":{"id":"OthJAaAdUZ3l"}},{"cell_type":"markdown","source":["# 3.1. Data Loading\n","First we need to import all the packages that we are going to need for the project."],"metadata":{"id":"vZl9MKC0Thhp"}},{"cell_type":"code","source":["from google.colab import drive\n","from PIL import Image\n","\n","import os\n","import cv2\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import torch\n","import torchvision\n","import time\n","import random\n","import pandas as pd"],"metadata":{"id":"DyBxe0tmV00u","executionInfo":{"status":"ok","timestamp":1767902393919,"user_tz":-60,"elapsed":32,"user":{"displayName":"Ander Bodegas Díez","userId":"03076711932678336016"}}},"execution_count":28,"outputs":[]},{"cell_type":"markdown","source":["Then, we mount the drive to get access to the dataset."],"metadata":{"id":"aYvluWxsXiR4"}},{"cell_type":"code","source":["drive.mount('/content/drive')\n","pathRoot = '/content/drive/MyDrive/Colab Notebooks/Admeav/FinalProjectAdmeav'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6yAbfdTDWDRV","executionInfo":{"status":"ok","timestamp":1767902395019,"user_tz":-60,"elapsed":1090,"user":{"displayName":"Ander Bodegas Díez","userId":"03076711932678336016"}},"outputId":"0100abae-0774-42e5-abe3-470ada4cfc9e"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"markdown","source":["# 3.2. PyTorch Dataset\n","\n","In the last section, we preprocessed and structured the data as follows:\n","- DATASET\n","  - TRAIN\n","    - IMAGES\n","    - MASKS\n","  - VALIDATION\n","    - IMAGES\n","    - MASKS\n","  - TEST\n","    - IMAGES\n","    - MASKS\n","\n","In order to train, validate and test a segmentation model we first need to create a PyTorch dataset to read each image and its mask."],"metadata":{"id":"tN5wmKbqTqYJ"}},{"cell_type":"code","source":["class BreastCancerDataset(torch.utils.data.Dataset):\n","  def __init__(self, fol: str, tra = None):\n","    super(BreastCancerDataset, self).__init__()\n","    self.imgFol = os.path.join(fol, 'IMAGES')\n","    self.masFol = os.path.join(fol, 'MASKS')\n","    self.tra = tra\n","    self.imgLis = os.listdir(self.imgFol)\n","\n","  def __getitem__(self, idx):\n","\n","    # Read image\n","    img = cv2.imread(\n","      filename = os.path.join(self.imgFol, self.imgLis[idx]),\n","      flags = cv2.IMREAD_UNCHANGED\n","    )\n","    img = Image.fromarray(img)\n","\n","    # Read mask\n","    mas = cv2.imread(\n","      filename = os.path.join(self.masFol, self.imgLis[idx]),\n","      flags = cv2.IMREAD_UNCHANGED\n","    )\n","    mas = torch.from_numpy(mas / 255).to(dtype = torch.long)\n","\n","    # Apply transformation to image if given\n","    if self.tra:\n","      img = self.tra(img)\n","\n","    return img, mas\n","\n","  def __len__(self):\n","      return len(self.imgLis)"],"metadata":{"id":"Lm6aoxkHiVyi","executionInfo":{"status":"ok","timestamp":1767902395062,"user_tz":-60,"elapsed":29,"user":{"displayName":"Ander Bodegas Díez","userId":"03076711932678336016"}}},"execution_count":30,"outputs":[]},{"cell_type":"markdown","source":["# 3.3. Model Architecture\n","\n","Now we need to define the segmentation models."],"metadata":{"id":"WslH5ajijqmE"}},{"cell_type":"code","source":["def convBlock(inChannels: int, outChannels: int, k: int):\n","  return torch.nn.Sequential(\n","    torch.nn.Conv2d(\n","      in_channels = inChannels,\n","      out_channels = outChannels,\n","      kernel_size = (k, k),\n","      stride = 1,\n","      padding = 'same'\n","    ),\n","    torch.nn.BatchNorm2d(outChannels),\n","    torch.nn.ReLU(),\n","    torch.nn.Conv2d(\n","      in_channels = outChannels,\n","      out_channels = outChannels,\n","      kernel_size = (3, 3),\n","      stride = 1,\n","      padding = 'same'\n","    ),\n","    torch.nn.BatchNorm2d(outChannels),\n","    torch.nn.ReLU()\n","  )\n","\n","#------------------------------------------------------------------------------#\n","\n","def up(inChannels: int, outChannels: int, k: int):\n","  return torch.nn.Sequential(\n","    torch.nn.ConvTranspose2d(\n","      in_channels = inChannels,\n","      out_channels = outChannels,\n","      kernel_size = (k, k),\n","      stride = k\n","    )\n","  )\n","\n","#------------------------------------------------------------------------------#\n","\n","class Encoder(torch.nn.Module):\n","  def __init__(\n","    self,\n","    inChannels: int = 1,\n","    initChannels: int = 16,\n","    depthLevels: int = 4\n","  ):\n","    super(Encoder, self).__init__()\n","    self.depthLevels = depthLevels\n","\n","    # Initialize list of modules\n","    self.layers = torch.nn.ModuleList()\n","\n","    # Initialize out channels\n","    outChannels = initChannels\n","\n","    # Loop to generate all layers\n","    for i in range(depthLevels):\n","\n","      # Convolutional block\n","      self.layers.append(\n","        convBlock(\n","          inChannels = inChannels,\n","          outChannels = outChannels,\n","          k = 3\n","        )\n","      )\n","\n","      # Max pooling\n","      self.layers.append(\n","        torch.nn.MaxPool2d(kernel_size = (2, 2), stride = 2)\n","      )\n","\n","      # Update in and out channels\n","      inChannels = outChannels\n","      outChannels = outChannels * 2\n","\n","    # Bottle neck (last layer of the encoder)\n","    self.layers.append(\n","      convBlock(\n","        inChannels = inChannels,\n","        outChannels = outChannels,\n","        k = 3\n","      )\n","    )\n","\n","    # Save feature dimensions\n","    self.featureDim = outChannels\n","\n","  def forward(self, x: torch.tensor):\n","    features = list()\n","\n","    # Forward loop\n","    for i in range(self.depthLevels):\n","      x = self.layers[2 * i](x)\n","      features.append(x)\n","      x = self.layers[2 * i + 1](x)\n","    x = torch.nn.Dropout(0.2)(self.layers[-1](x))\n","    features.append(x)\n","    return features\n","\n","#------------------------------------------------------------------------------#\n","\n","class Decoder(torch.nn.Module):\n","  def __init__(\n","    self,\n","    inChannels: int,\n","    nClasses: int = 1,\n","    depthLevels: int = 4,\n","    skipConnections: bool = True\n","  ):\n","    super(Decoder, self).__init__()\n","    self.depthLevels = depthLevels\n","    self.skipConnections = skipConnections\n","\n","    # Initialize list of modules\n","    self.layers = torch.nn.ModuleList()\n","\n","    # Initialize out channels\n","    outChannels = inChannels // 2\n","\n","    # Loop to generate all layers\n","    for _ in range(depthLevels):\n","\n","      # Up block\n","      self.layers.append(\n","        up(\n","          inChannels = inChannels,\n","          outChannels = outChannels,\n","          k = 2\n","        )\n","      )\n","\n","      # Convolutional block\n","      self.layers.append(\n","        convBlock(\n","          inChannels = outChannels * 2 if self.skipConnections else outChannels,\n","          outChannels = outChannels,\n","          k = 3\n","        )\n","      )\n","\n","      # Update in and out channels\n","      inChannels = outChannels\n","      outChannels = inChannels // 2\n","\n","    # Final (last layer of the decoder)\n","    self.layers.append(\n","      torch.nn.Conv2d(\n","        in_channels = inChannels,\n","        out_channels = nClasses,\n","        kernel_size = (3, 3),\n","        stride = 1,\n","        padding = 'same'\n","      )\n","    )\n","\n","  def forward(self, features: list):\n","\n","    # Get bottleneck features\n","    x = features[-1]\n","\n","    # Forward loop with or without skip-connections\n","    for i in range(self.depthLevels):\n","      x = self.layers[2 * i](x)\n","      if self.skipConnections:\n","        x = torch.cat([x, features[-(i + 2)]], dim = 1)\n","      x = self.layers[2 * i + 1](x)\n","    return self.layers[-1](x)\n","\n","#-----------------------------------------------------------------------------#\n","\n","class UNet(torch.nn.Module):\n","  def __init__(\n","    self,\n","    inChannels: int = 3,\n","    nClasses: int = 1,\n","    initChannels: int = 16,\n","    depthLevels: int = 4,\n","    skipConnections: bool = True\n","  ):\n","    super(UNet, self).__init__()\n","\n","    # Encoder\n","    self.encoder = Encoder(\n","      inChannels = inChannels,\n","      initChannels = initChannels,\n","      depthLevels = depthLevels\n","    )\n","\n","    # Decoder\n","    self.decoder = Decoder(\n","      inChannels = self.encoder.featureDim,\n","      nClasses = nClasses,\n","      depthLevels = depthLevels,\n","      skipConnections = skipConnections\n","    )\n","\n","  def forward(self, x: torch.tensor):\n","    features = self.encoder(x)\n","    return self.decoder(features)\n"],"metadata":{"id":"26UjZKAE9Sra","executionInfo":{"status":"ok","timestamp":1767902395092,"user_tz":-60,"elapsed":7,"user":{"displayName":"Ander Bodegas Díez","userId":"03076711932678336016"}}},"execution_count":31,"outputs":[]},{"cell_type":"markdown","source":["# 3.4. Training model\n"],"metadata":{"id":"ifrSHlwW96ic"}},{"cell_type":"code","source":["def diceCELoss(preds: torch.Tensor, targs: torch.Tensor):\n","\n","  # Compute probabilities with a sigmoid function\n","  preds = torch.sigmoid(preds[:, 0])\n","\n","  # Compute binary cross entropy\n","  bce = torch.nn.functional.binary_cross_entropy_with_logits(preds, targs.float())\n","\n","  # Compute intersection and union\n","  inter = (preds * targs).sum()\n","  union = preds.sum() + targs.sum()\n","\n","  # Compute dice and return 1 - dice\n","  dice = (2 * inter + 1e-6) / (union + 1e-6)\n","\n","  return 0.8 * (1 - dice) + 0.4 * bce"],"metadata":{"id":"VzFZu2Pz-eER","executionInfo":{"status":"ok","timestamp":1767902395101,"user_tz":-60,"elapsed":5,"user":{"displayName":"Ander Bodegas Díez","userId":"03076711932678336016"}}},"execution_count":32,"outputs":[]},{"cell_type":"code","source":["def train(\n","  model: torch.nn.Module,\n","  optimizer,\n","  criterion,\n","  epochs: int,\n","  dlT: torch.utils.data.DataLoader,\n","  dlV: torch.utils.data.DataLoader,\n","  dev: torch.DeviceObjType\n","):\n","\n","  # Number of steps for the training and validation dataset\n","  stepsT = len(dlT)\n","  stepsV = len(dlV)\n","\n","  # Logs dataframe\n","  logs = {\n","    'epoch': list(),\n","    'time': list(),\n","    'lossT': list(),\n","    'lossV': list()\n","  }\n","\n","  # Move model to device\n","  model.to(device = dev)\n","\n","  # Traing loop\n","  for epoch in range(epochs):\n","\n","    # Initialize time\n","    t0 = time.time()\n","\n","    # Update logs\n","    logs['epoch'].append(epoch)\n","    logs['lossT'].append(0)\n","    logs['lossV'].append(0)\n","\n","    # Set model in training mode\n","    model.train()\n","\n","    # Training batch loop\n","    for batch in dlT:\n","\n","      # Read batch and move to device\n","      img, mas = batch\n","      img = img.to(device = dev)\n","      mas = mas.to(device = dev)\n","\n","      # Reset gradient\n","      optimizer.zero_grad()\n","\n","      # Forward pass\n","      preds = model(img)\n","\n","      # Compute loss\n","      loss = criterion(preds, mas)\n","\n","      # Backward pass\n","      loss.backward()\n","      optimizer.step()\n","\n","      # Update logs\n","      logs['lossT'][-1] += loss.item()\n","\n","    # Set model in evaluation mode\n","    model.eval()\n","\n","    # Disable gradient calculations\n","    with torch.no_grad():\n","\n","      # Validation batch loop\n","      for batch in dlV:\n","\n","        # Read batch and move to device\n","        img, mas = batch\n","        img = img.to(device = dev)\n","        mas = mas.to(device = dev)\n","\n","        # Forward pass\n","        preds = model(img)\n","\n","        # Compute loss\n","        loss = criterion(preds, mas)\n","\n","        # Update logs\n","        logs['lossV'][-1] += loss.item()\n","\n","      # Update logs based on the number of steps\n","      logs['lossT'][-1] /= stepsT\n","      logs['lossV'][-1] /= stepsV\n","\n","    # Calculate time\n","    t1 = time.time()\n","    t = (t1 - t0) / 60.0\n","    logs['time'].append(t)\n","\n","    # Print progress\n","    print((\n","      f'Epoch [{epoch} / {epochs}] | '\n","      f'Time: {logs['time'][-1]: .2f} | '\n","      f'T. Loss: {logs['lossT'][-1]: .2f} | '\n","      f'V. Loss: {logs['lossV'][-1]: .2f} | '\n","    ))\n","\n","  return logs"],"metadata":{"id":"rTjlx5qd-Fx1","executionInfo":{"status":"ok","timestamp":1767902395109,"user_tz":-60,"elapsed":3,"user":{"displayName":"Ander Bodegas Díez","userId":"03076711932678336016"}}},"execution_count":33,"outputs":[]},{"cell_type":"code","source":["# Check device\n","dev = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(f'Device: {dev}')\n","\n","# Model initialization\n","model = UNet(inChannels = 3, nClasses = 1, initChannels = 16, depthLevels = 4)\n","\n","# Base dataset\n","dsT = BreastCancerDataset(\n","  fol = os.path.join(pathRoot, 'DATASET/TRAIN'),\n","  tra = torchvision.transforms.ToTensor()\n",")\n","dsV = BreastCancerDataset(\n","  fol = os.path.join(pathRoot, 'DATASET/VALIDATION'),\n","  tra = torchvision.transforms.ToTensor()\n",")\n","\n","# Set seed for reproducibility\n","torch.manual_seed(42)\n","\n","# Dataloaders\n","dlT = torch.utils.data.DataLoader(\n","  dataset = dsT,\n","  batch_size = 16,\n","  shuffle = True\n",")\n","dlV = torch.utils.data.DataLoader(\n","  dataset = dsV,\n","  batch_size = 16,\n","  shuffle = False\n",")\n","\n","# Define criterion and optimizer\n","criterion = diceCELoss\n","optimizer = torch.optim.AdamW(\n","  params = model.parameters(),\n","  lr = 1e-3,\n","  weight_decay = 1e-4\n",")\n","\n","# Train\n","logs = train(\n","  model = model,\n","  optimizer = optimizer,\n","  criterion = criterion,\n","  epochs = 100,\n","  dlT = dlT,\n","  dlV = dlV,\n","  dev = dev\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CklRG1u9-Y_X","outputId":"a39319a5-2a13-4078-bfaf-a79003456fec","executionInfo":{"status":"ok","timestamp":1767905775280,"user_tz":-60,"elapsed":3380167,"user":{"displayName":"Ander Bodegas Díez","userId":"03076711932678336016"}}},"execution_count":34,"outputs":[{"output_type":"stream","name":"stdout","text":["Device: cuda\n","Epoch [0 / 100] | Time:  0.58 | T. Loss:  0.99 | V. Loss:  0.98 | \n","Epoch [1 / 100] | Time:  0.57 | T. Loss:  0.87 | V. Loss:  1.00 | \n","Epoch [2 / 100] | Time:  0.56 | T. Loss:  0.82 | V. Loss:  1.04 | \n","Epoch [3 / 100] | Time:  0.56 | T. Loss:  0.75 | V. Loss:  0.91 | \n","Epoch [4 / 100] | Time:  0.56 | T. Loss:  0.72 | V. Loss:  0.73 | \n","Epoch [5 / 100] | Time:  0.56 | T. Loss:  0.69 | V. Loss:  0.66 | \n","Epoch [6 / 100] | Time:  0.56 | T. Loss:  0.67 | V. Loss:  0.86 | \n","Epoch [7 / 100] | Time:  0.56 | T. Loss:  0.69 | V. Loss:  0.81 | \n","Epoch [8 / 100] | Time:  0.56 | T. Loss:  0.67 | V. Loss:  0.62 | \n","Epoch [9 / 100] | Time:  0.57 | T. Loss:  0.66 | V. Loss:  0.64 | \n","Epoch [10 / 100] | Time:  0.56 | T. Loss:  0.66 | V. Loss:  0.61 | \n","Epoch [11 / 100] | Time:  0.57 | T. Loss:  0.64 | V. Loss:  0.72 | \n","Epoch [12 / 100] | Time:  0.55 | T. Loss:  0.64 | V. Loss:  0.62 | \n","Epoch [13 / 100] | Time:  0.56 | T. Loss:  0.65 | V. Loss:  0.71 | \n","Epoch [14 / 100] | Time:  0.56 | T. Loss:  0.62 | V. Loss:  0.57 | \n","Epoch [15 / 100] | Time:  0.56 | T. Loss:  0.63 | V. Loss:  0.58 | \n","Epoch [16 / 100] | Time:  0.56 | T. Loss:  0.63 | V. Loss:  0.56 | \n","Epoch [17 / 100] | Time:  0.56 | T. Loss:  0.61 | V. Loss:  0.63 | \n","Epoch [18 / 100] | Time:  0.57 | T. Loss:  0.62 | V. Loss:  0.68 | \n","Epoch [19 / 100] | Time:  0.56 | T. Loss:  0.61 | V. Loss:  0.61 | \n","Epoch [20 / 100] | Time:  0.56 | T. Loss:  0.60 | V. Loss:  0.55 | \n","Epoch [21 / 100] | Time:  0.57 | T. Loss:  0.60 | V. Loss:  0.57 | \n","Epoch [22 / 100] | Time:  0.56 | T. Loss:  0.58 | V. Loss:  0.62 | \n","Epoch [23 / 100] | Time:  0.56 | T. Loss:  0.59 | V. Loss:  0.73 | \n","Epoch [24 / 100] | Time:  0.56 | T. Loss:  0.59 | V. Loss:  0.59 | \n","Epoch [25 / 100] | Time:  0.56 | T. Loss:  0.57 | V. Loss:  0.52 | \n","Epoch [26 / 100] | Time:  0.57 | T. Loss:  0.56 | V. Loss:  0.50 | \n","Epoch [27 / 100] | Time:  0.55 | T. Loss:  0.57 | V. Loss:  0.59 | \n","Epoch [28 / 100] | Time:  0.57 | T. Loss:  0.56 | V. Loss:  0.56 | \n","Epoch [29 / 100] | Time:  0.56 | T. Loss:  0.57 | V. Loss:  0.53 | \n","Epoch [30 / 100] | Time:  0.56 | T. Loss:  0.58 | V. Loss:  0.51 | \n","Epoch [31 / 100] | Time:  0.57 | T. Loss:  0.56 | V. Loss:  0.58 | \n","Epoch [32 / 100] | Time:  0.56 | T. Loss:  0.56 | V. Loss:  0.57 | \n","Epoch [33 / 100] | Time:  0.56 | T. Loss:  0.56 | V. Loss:  0.53 | \n","Epoch [34 / 100] | Time:  0.56 | T. Loss:  0.55 | V. Loss:  0.55 | \n","Epoch [35 / 100] | Time:  0.57 | T. Loss:  0.56 | V. Loss:  0.54 | \n","Epoch [36 / 100] | Time:  0.57 | T. Loss:  0.54 | V. Loss:  0.56 | \n","Epoch [37 / 100] | Time:  0.56 | T. Loss:  0.55 | V. Loss:  0.51 | \n","Epoch [38 / 100] | Time:  0.56 | T. Loss:  0.54 | V. Loss:  0.51 | \n","Epoch [39 / 100] | Time:  0.56 | T. Loss:  0.54 | V. Loss:  0.50 | \n","Epoch [40 / 100] | Time:  0.56 | T. Loss:  0.54 | V. Loss:  0.50 | \n","Epoch [41 / 100] | Time:  0.56 | T. Loss:  0.53 | V. Loss:  0.58 | \n","Epoch [42 / 100] | Time:  0.56 | T. Loss:  0.53 | V. Loss:  0.49 | \n","Epoch [43 / 100] | Time:  0.57 | T. Loss:  0.54 | V. Loss:  0.61 | \n","Epoch [44 / 100] | Time:  0.56 | T. Loss:  0.52 | V. Loss:  0.53 | \n","Epoch [45 / 100] | Time:  0.57 | T. Loss:  0.55 | V. Loss:  0.54 | \n","Epoch [46 / 100] | Time:  0.57 | T. Loss:  0.53 | V. Loss:  0.56 | \n","Epoch [47 / 100] | Time:  0.57 | T. Loss:  0.52 | V. Loss:  0.50 | \n","Epoch [48 / 100] | Time:  0.56 | T. Loss:  0.51 | V. Loss:  0.49 | \n","Epoch [49 / 100] | Time:  0.56 | T. Loss:  0.52 | V. Loss:  0.54 | \n","Epoch [50 / 100] | Time:  0.56 | T. Loss:  0.52 | V. Loss:  0.52 | \n","Epoch [51 / 100] | Time:  0.56 | T. Loss:  0.50 | V. Loss:  0.49 | \n","Epoch [52 / 100] | Time:  0.56 | T. Loss:  0.49 | V. Loss:  0.48 | \n","Epoch [53 / 100] | Time:  0.57 | T. Loss:  0.50 | V. Loss:  0.50 | \n","Epoch [54 / 100] | Time:  0.56 | T. Loss:  0.49 | V. Loss:  0.54 | \n","Epoch [55 / 100] | Time:  0.57 | T. Loss:  0.50 | V. Loss:  0.56 | \n","Epoch [56 / 100] | Time:  0.57 | T. Loss:  0.49 | V. Loss:  0.50 | \n","Epoch [57 / 100] | Time:  0.56 | T. Loss:  0.47 | V. Loss:  0.49 | \n","Epoch [58 / 100] | Time:  0.57 | T. Loss:  0.47 | V. Loss:  0.49 | \n","Epoch [59 / 100] | Time:  0.56 | T. Loss:  0.47 | V. Loss:  0.48 | \n","Epoch [60 / 100] | Time:  0.57 | T. Loss:  0.48 | V. Loss:  0.49 | \n","Epoch [61 / 100] | Time:  0.56 | T. Loss:  0.48 | V. Loss:  0.54 | \n","Epoch [62 / 100] | Time:  0.57 | T. Loss:  0.47 | V. Loss:  0.49 | \n","Epoch [63 / 100] | Time:  0.56 | T. Loss:  0.46 | V. Loss:  0.49 | \n","Epoch [64 / 100] | Time:  0.57 | T. Loss:  0.46 | V. Loss:  0.52 | \n","Epoch [65 / 100] | Time:  0.57 | T. Loss:  0.46 | V. Loss:  0.55 | \n","Epoch [66 / 100] | Time:  0.56 | T. Loss:  0.46 | V. Loss:  0.49 | \n","Epoch [67 / 100] | Time:  0.56 | T. Loss:  0.44 | V. Loss:  0.48 | \n","Epoch [68 / 100] | Time:  0.57 | T. Loss:  0.43 | V. Loss:  0.49 | \n","Epoch [69 / 100] | Time:  0.56 | T. Loss:  0.45 | V. Loss:  0.49 | \n","Epoch [70 / 100] | Time:  0.56 | T. Loss:  0.45 | V. Loss:  0.52 | \n","Epoch [71 / 100] | Time:  0.56 | T. Loss:  0.44 | V. Loss:  0.47 | \n","Epoch [72 / 100] | Time:  0.56 | T. Loss:  0.44 | V. Loss:  0.52 | \n","Epoch [73 / 100] | Time:  0.56 | T. Loss:  0.44 | V. Loss:  0.53 | \n","Epoch [74 / 100] | Time:  0.56 | T. Loss:  0.44 | V. Loss:  0.48 | \n","Epoch [75 / 100] | Time:  0.56 | T. Loss:  0.43 | V. Loss:  0.48 | \n","Epoch [76 / 100] | Time:  0.56 | T. Loss:  0.41 | V. Loss:  0.49 | \n","Epoch [77 / 100] | Time:  0.57 | T. Loss:  0.42 | V. Loss:  0.62 | \n","Epoch [78 / 100] | Time:  0.57 | T. Loss:  0.43 | V. Loss:  0.49 | \n","Epoch [79 / 100] | Time:  0.56 | T. Loss:  0.42 | V. Loss:  0.48 | \n","Epoch [80 / 100] | Time:  0.57 | T. Loss:  0.41 | V. Loss:  0.49 | \n","Epoch [81 / 100] | Time:  0.55 | T. Loss:  0.43 | V. Loss:  0.55 | \n","Epoch [82 / 100] | Time:  0.57 | T. Loss:  0.44 | V. Loss:  0.49 | \n","Epoch [83 / 100] | Time:  0.57 | T. Loss:  0.40 | V. Loss:  0.48 | \n","Epoch [84 / 100] | Time:  0.56 | T. Loss:  0.42 | V. Loss:  0.50 | \n","Epoch [85 / 100] | Time:  0.57 | T. Loss:  0.41 | V. Loss:  0.49 | \n","Epoch [86 / 100] | Time:  0.56 | T. Loss:  0.41 | V. Loss:  0.50 | \n","Epoch [87 / 100] | Time:  0.57 | T. Loss:  0.40 | V. Loss:  0.51 | \n","Epoch [88 / 100] | Time:  0.55 | T. Loss:  0.39 | V. Loss:  0.50 | \n","Epoch [89 / 100] | Time:  0.57 | T. Loss:  0.40 | V. Loss:  0.58 | \n","Epoch [90 / 100] | Time:  0.56 | T. Loss:  0.41 | V. Loss:  0.51 | \n","Epoch [91 / 100] | Time:  0.56 | T. Loss:  0.39 | V. Loss:  0.50 | \n","Epoch [92 / 100] | Time:  0.56 | T. Loss:  0.39 | V. Loss:  0.48 | \n","Epoch [93 / 100] | Time:  0.56 | T. Loss:  0.38 | V. Loss:  0.52 | \n","Epoch [94 / 100] | Time:  0.56 | T. Loss:  0.41 | V. Loss:  0.49 | \n","Epoch [95 / 100] | Time:  0.56 | T. Loss:  0.40 | V. Loss:  0.50 | \n","Epoch [96 / 100] | Time:  0.57 | T. Loss:  0.39 | V. Loss:  0.51 | \n","Epoch [97 / 100] | Time:  0.57 | T. Loss:  0.39 | V. Loss:  0.50 | \n","Epoch [98 / 100] | Time:  0.56 | T. Loss:  0.38 | V. Loss:  0.48 | \n","Epoch [99 / 100] | Time:  0.57 | T. Loss:  0.37 | V. Loss:  0.50 | \n"]}]}]}